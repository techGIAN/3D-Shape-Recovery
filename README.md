# 3D-Shape-Recovery
Implementation from scratch of Learning 3D Shape Recovery using Point Cloud Module and Depth Monocular Prediction

### Datasets

<ul>
  <li> <b>Taskonomy</b>: available <a href="https://github.com/StanfordVL/taskonomy/tree/master/data">here</a>. This is the main dataset that was used on to train PCM and DPM modules. It is comprised of large and high-quality images of varied indoor scenes. It is 11.16 TB in size but we are only using a subset (RGB dataset for DPM, 512x512 resolution; depth_zbuffer dataset for PCM, z-buffer depth images) </li>
</ul>

#### Other Potential Datasets

<ul>
   <li> <b>ScanNet</b>: available <a href="https://github.com/ScanNet/ScanNet">here</a> </li>
  <li> <b>DIML</b>: <a href="http://diml.yonsei.ac.kr/DIML_rgbd_dataset/">here</a>, but link is broken </li>
  <li> <b>Ken Burns</b>: available <a href="https://github.com/sniklaus/3d-ken-burns">here</a> </li>
</ul>

#### Testing Datasets

<ul>
  <li> <b>Youtube3D</b>: available <a href="http://www-personal.umich.edu/~wfchen/depth-in-the-wild/">here</a> </li>
</ul>
